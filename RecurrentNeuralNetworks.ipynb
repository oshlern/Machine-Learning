{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note_: The three exercises in this tutorial can be done in any order. Decide which interests you the most, and start with that one. You don't have to do all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "1. If you haven't already installed Python3, get it from [Python.org](https://www.python.org/downloads/)\n",
    "1. If you haven't already installed Jupyter Notebook, run `python3 -m pip install jupyter`\n",
    "1. In Terminal, cd to the folder in which you downloaded this file and run `jupyter notebook`. This should open up a page in your web browser that shows all of the files in the current directory, so that you can open this file. You will need to leave this Terminal window up and running and use a different one for the rest of the instructions.\n",
    "1. If you didn't install keras previously, install it now\n",
    "    1. Install the tensorflow machine learning library by typing the following into Terminal:\n",
    "    `pip3 install --upgrade tensorflow`\n",
    "    1. Install the keras machine learning library by typing the following into Terminal:\n",
    "    `pip3 install keras`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation/Sources\n",
    "* [https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/](https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/) for information on sequence classification with keras\n",
    "* [https://keras.io/](https://keras.io/) Keras API documentation\n",
    "* [Keras recurrent tutorial](https://github.com/Vict0rSch/deep_learning/tree/master/keras/recurrent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The IMDB Dataset\n",
    "The [IMDB dataset](https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification) consists of movie reviews (x_train) that have been marked as positive or negative (y_train). See the [Word Vectors Tutorial](https://github.com/jennselby/MachineLearningTutorials/blob/master/WordVectors.ipynb) for more details on the IMDB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(imdb_x_train, imdb_y_train), (imdb_x_test, imdb_y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb_y_test_reverse = np.subtract(1, imdb_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a standard keras model, every input has to be the same length, so we need to set some length after which we will cutoff the rest of the review. (We will also need to pad the shorter reviews with zeros to make them the same length)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our model.\n",
    "\n",
    "Unlike last time, when we used convolutional layers, we're going to use an LSTM, a special type of recurrent network.\n",
    "\n",
    "Using recurrent networks means that rather than seeing these reviews as one input happening all at one, with the convolutional layers taking into account which words are next to each other, we are going to see them as a sequence of inputs, with one word occurring at each timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cutoff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-04b71e26f1cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimdb_lstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimdb_lstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# return_sequences tells the LSTM to output the full sequence, for use by the next LSTM layer. The final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# LSTM layer should return only the output sequence, for use in the Dense output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimdb_lstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cutoff' is not defined"
     ]
    }
   ],
   "source": [
    "imdb_lstm_model = Sequential()\n",
    "imdb_lstm_model.add(Embedding(input_dim=len(imdb.get_word_index())+3, output_dim=100, input_length=cutoff))\n",
    "# return_sequences tells the LSTM to output the full sequence, for use by the next LSTM layer. The final\n",
    "# LSTM layer should return only the output sequence, for use in the Dense output layer\n",
    "imdb_lstm_model.add(LSTM(units=32, return_sequences=True))\n",
    "imdb_lstm_model.add(LSTM(units=32))\n",
    "imdb_lstm_model.add(Dense(units=1, activation='sigmoid')) # because at the end, we want one yes/no answer\n",
    "imdb_lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model. __This takes awhile. You might not want to re-run it.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb_lstm_model.fit(imdb_x_train_padded, imdb_y_train, epochs=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the model. __This takes awhile. You might not want to re-run it.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb_lstm_scores = imdb_lstm_model.evaluate(imdb_x_test_padded, imdb_y_test)\n",
    "print('loss: {} accuracy: {}'.format(*imdb_lstm_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Experiment with different model configurations from the one above. Try other recurrent layers, different numbers of layers, change some of the defaults. See [Keras Recurrent Layers](https://keras.io/layers/recurrent/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cutoff = 500\n",
    "out_dim = 80\n",
    "units = 40\n",
    "dropout_1 = 0.14\n",
    "dropout_2 = 0.01\n",
    "activation_1 = 'selu'\n",
    "activation_2 = 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb_x_train_padded = sequence.pad_sequences(imdb_x_train, maxlen=cutoff)\n",
    "imdb_x_test_padded = sequence.pad_sequences(imdb_x_test, maxlen=cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(imdb.get_word_index())+3, output_dim=out_dim, input_length=cutoff))\n",
    "# return_sequences tells the LSTM to output the full sequence, for use by the next LSTM layer. The final\n",
    "# LSTM layer should return only the output sequence, for use in the Dense output layer\n",
    "model.add(LSTM(units=40, activation=activation_1, return_sequences=True))#dropout=dropout_1)\n",
    "model.add(LSTM(units=40, activation=activation_2)) #dropout=dropout_2))\n",
    "model.add(Dense(units=1, activation='sigmoid')) # because at the end, we want one yes/no answer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 343s 14ms/step - loss: nan - binary_accuracy: 0.0810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x123e310f0>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(imdb_x_train_padded, imdb_y_train, epochs=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 96s 4ms/step\n",
      "loss: nan accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(imdb_x_test_padded, imdb_y_test_reverse)\n",
    "print('loss: {} accuracy: {}'.format(*scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7584/25000 [========>.....................] - ETA: 1:02"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-76cf6e2d7c95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdb_x_test_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimdb_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss: {} accuracy: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m                                    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m                                    steps=steps)\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1742\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m                                \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1744\u001b[0;31m                                steps=steps)\n\u001b[0m\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1380\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(imdb_x_test_padded, imdb_y_test)\n",
    "print('loss: {} accuracy: {}'.format(*scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       ...,\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(imdb_x_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 0, ..., 1, 1, 1]), array([0, 1, 1, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_y_test_reverse, imdb_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Simple Recurrent Layers\n",
    "\n",
    "Before we dive into something as complicated as LSTMs, Let's take a deeper look at simple recurrent layer weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.layers import SimpleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neurons in the recurrent layer pass their output to the next layer, but also back to themselves. The input shape says that we'll be passing in one-dimensional inputs of unspecified length (the None is what makes it unspecified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_unit_SRNN = Sequential()\n",
    "one_unit_SRNN.add(SimpleRNN(units=1, input_shape=(None, 1), activation='linear', use_bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.366263]], dtype=float32), array([[1.]], dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_SRNN_weights = one_unit_SRNN.get_weights()\n",
    "one_unit_SRNN_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.]], dtype=float32), array([[1.]], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_SRNN_weights[0][0][0] = 1\n",
    "one_unit_SRNN_weights[1][0][0] = 1\n",
    "one_unit_SRNN.set_weights(one_unit_SRNN_weights)\n",
    "one_unit_SRNN.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This passes in a single sample that has three time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_SRNN.predict(numpy.array([ [[3], [3], [7]] ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2a\n",
    "Figure out what the two weights in the one_unit_SRNN model control. Be sure to test your hypothesis thoroughly. Use different weights and different inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.]], dtype=float32), array([[0.1]], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_SRNN_weights[0][0][0] = 1\n",
    "one_unit_SRNN_weights[1][0][0] = 0.1\n",
    "one_unit_SRNN.set_weights(one_unit_SRNN_weights)\n",
    "one_unit_SRNN.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.33]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_SRNN.predict(numpy.array([ [[3], [3], [7]] ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a slightly larger simple recurrent model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "two_unit_SRNN = Sequential()\n",
    "two_unit_SRNN.add(SimpleRNN(units=2, input_shape=(None, 1), activation='linear', use_bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.8075575,  1.1117176]], dtype=float32),\n",
       " array([[-0.7666786 ,  0.64203113],\n",
       "        [ 0.64203113,  0.7666786 ]], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_unit_SRNN_weights = two_unit_SRNN.get_weights()\n",
    "two_unit_SRNN_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 1.]], dtype=float32), array([[0., 1.],\n",
       "        [0., 1.]], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_unit_SRNN_weights[0][0][0] = 1\n",
    "two_unit_SRNN_weights[0][0][1] = 1\n",
    "two_unit_SRNN_weights[1][0][0] = 0\n",
    "two_unit_SRNN_weights[1][0][1] = 1\n",
    "two_unit_SRNN_weights[1][1][0] = 0\n",
    "two_unit_SRNN_weights[1][1][1] = 1\n",
    "two_unit_SRNN.set_weights(two_unit_SRNN_weights)\n",
    "two_unit_SRNN.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This passes in a single sample with four time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5., 31.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_unit_SRNN.predict(numpy.array([ [[3], [3], [7], [5]] ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2b\n",
    "What do each of the six weights of the two_unit_SRNN control? Again, test out your hypotheses carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 2.]], dtype=float32), array([[0.1 , 0.  ],\n",
       "        [0.  , 0.01]], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_unit_SRNN_weights[0][0][0] = 1\n",
    "two_unit_SRNN_weights[0][0][1] = 2\n",
    "two_unit_SRNN_weights[1][0][0] = 0.1\n",
    "two_unit_SRNN_weights[1][0][1] = 0\n",
    "two_unit_SRNN_weights[1][1][0] = 0\n",
    "two_unit_SRNN_weights[1][1][1] = 0.01\n",
    "two_unit_SRNN.set_weights(two_unit_SRNN_weights)\n",
    "two_unit_SRNN.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.733   , 10.140606]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_unit_SRNN.predict(numpy.array([ [[3], [3], [7], [5]] ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 0.]], dtype=float32), array([[1.e-01, 1.e+00],\n",
       "        [1.e-05, 1.e-04]], dtype=float32)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_unit_SRNN_weights[0][0][0] = 1\n",
    "two_unit_SRNN_weights[0][0][1] = 0\n",
    "two_unit_SRNN_weights[1][0][0] = 0.1\n",
    "two_unit_SRNN_weights[1][0][1] = 1\n",
    "two_unit_SRNN_weights[1][1][0] = 0.00001\n",
    "two_unit_SRNN_weights[1][1][1] = 0.0001\n",
    "two_unit_SRNN.set_weights(two_unit_SRNN_weights)\n",
    "two_unit_SRNN.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.733036, 7.33036 ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_unit_SRNN.predict(numpy.array([ [[3], [3], [7], [5]] ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the weights are organized by:\n",
    "\n",
    "weights[0] input\n",
    "\n",
    "weights[1] last output\n",
    "\n",
    "weights[1][0] weight to be multiplied by the first element of last output\n",
    "\n",
    "weights[1][1] weight to be multiplied by the second element of last output\n",
    "\n",
    "weights[:][:][0] output to first element of output\n",
    "\n",
    "weights[:][:][1] output to second element of output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring LSTMs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_unit_LSTM = Sequential()\n",
    "one_unit_LSTM.add(LSTM(units=1, input_shape=(None, 1),\n",
    "                       activation='linear', recurrent_activation='linear',\n",
    "                       use_bias=False, unit_forget_bias=False,\n",
    "                       kernel_initializer='zeros',\n",
    "                       recurrent_initializer='zeros',\n",
    "                       return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 0., 0., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_LSTM_weights = one_unit_LSTM.get_weights()\n",
    "one_unit_LSTM_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 0., 1., 1.]], dtype=float32),\n",
       " array([[0., 0., 0., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_LSTM_weights[0][0][0] = 1\n",
    "one_unit_LSTM_weights[0][0][1] = 0\n",
    "one_unit_LSTM_weights[0][0][2] = 1\n",
    "one_unit_LSTM_weights[0][0][3] = 1\n",
    "one_unit_LSTM_weights[1][0][0] = 0\n",
    "one_unit_LSTM_weights[1][0][1] = 0\n",
    "one_unit_LSTM_weights[1][0][2] = 0\n",
    "one_unit_LSTM_weights[1][0][3] = 0\n",
    "one_unit_LSTM.set_weights(one_unit_LSTM_weights)\n",
    "one_unit_LSTM.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.],\n",
       "        [ 1.],\n",
       "        [ 8.],\n",
       "        [64.]]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_LSTM.predict(numpy.array([ [[0], [1], [2], [4]] ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2c\n",
    "Conceptually, the [LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) has several _gates_:\n",
    "\n",
    "* __Forget gate__: these weights allow some long-term memories to be forgotten.\n",
    "* __Input gate__: these weights decide what new information will be added to the context cell.\n",
    "* __Output gate__: these weights decide what pieces of the new information and updated context will be passed on to the output.\n",
    "\n",
    "It also has a __cell__ that can hold onto information from the current input (as well as things it has remembered from previous inputs), so that it can be used in later outputs.\n",
    "\n",
    "Identify which weights in the one_unit_LSTM model are connected with the context and which are associated with the three gates?\n",
    "\n",
    "_Note_: The output from the predict call is what the linked explanation calls $h_{t}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1. , 0.1, 1. , 1. ]], dtype=float32),\n",
       " array([[0., 2., 0., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_LSTM_weights[0][0][0] = 1\n",
    "one_unit_LSTM_weights[0][0][1] = 0.1\n",
    "one_unit_LSTM_weights[0][0][2] = 1\n",
    "one_unit_LSTM_weights[0][0][3] = 1\n",
    "one_unit_LSTM_weights[1][0][0] = 0\n",
    "one_unit_LSTM_weights[1][0][1] = 2\n",
    "one_unit_LSTM_weights[1][0][2] = 0\n",
    "one_unit_LSTM_weights[1][0][3] = 0\n",
    "one_unit_LSTM.set_weights(one_unit_LSTM_weights)\n",
    "one_unit_LSTM.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  1.      ],\n",
       "        [  3.1     ],\n",
       "        [ 20.529999],\n",
       "        [846.01465 ]]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_unit_LSTM.predict(numpy.array([ [[1], [1], [1], [1]] ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the weights are organized by:\n",
    "\n",
    "weights[0][0][0,2,3] input to memory weights (identical impact for all 3 with these linear activations)\n",
    "\n",
    "weights[0][0][1] forget weight\n",
    "\n",
    "weights[0][0][0] input weight\n",
    "\n",
    "weights[0][0][3] output weight\n",
    "\n",
    "weights[1] last output\n",
    "\n",
    "weights[1][0] weight to be multiplied by the first element of last output\n",
    "\n",
    "weights[1][1] weight to be multiplied by the second element of last output\n",
    "\n",
    "weights[:][:][0] output to first element of output\n",
    "\n",
    "weights[:][:][1] output to second element of output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "Take the model from exercise 1 (imdb_lstm_model) and modify it to classify the [Reuters data](https://keras.io/datasets/#reuters-newswire-topics-classification).\n",
    "\n",
    "Think about what you are trying to predict in this case, and how you will have to change your model to deal with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(reuters_x_train, reuters_y_train), (reuters_x_test, reuters_y_test) = reuters.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reuters_map = reuters.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reuters_x_train[0:5], reuters_y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest review: 2376 Shortest review: 2\n",
      "2032 reviews out of 11228 are over 220.\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(review) for review in list(reuters_x_train) + list(reuters_x_test)]\n",
    "print('Longest review: {} Shortest review: {}'.format(max(lengths), min(lengths)))\n",
    "\n",
    "cutoff = 220\n",
    "print('{} reviews out of {} are over {}.'.format(\n",
    "    sum([1 for length in lengths if length > cutoff]), \n",
    "    len(lengths), \n",
    "    cutoff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reuters_x_train_padded = sequence.pad_sequences(reuters_x_train, maxlen=cutoff)\n",
    "reuters_x_test_padded = sequence.pad_sequences(reuters_x_test, maxlen=cutoff)\n",
    "reuters_y_train_one_hot = np_utils.to_categorical(reuters_y_train)\n",
    "reuters_y_test_one_hot = np_utils.to_categorical(reuters_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters_y_test_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(reuters_map)+3, output_dim=100, input_length=cutoff))\n",
    "# return_sequences tells the LSTM to output the full sequence, for use by the next LSTM layer. The final\n",
    "# LSTM layer should return only the output sequence, for use in the Dense output layer\n",
    "model.add(LSTM(units=32, activation='relu', return_sequences=True))#dropout=dropout_1)\n",
    "model.add(LSTM(units=32, activation='relu')) #dropout=dropout_2))\n",
    "model.add(Dense(units=46, activation='sigmoid')) # because at the end, we want one yes/no answer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "8982/8982 [==============================] - 49s 5ms/step - loss: nan - categorical_accuracy: 0.0661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x127e5b438>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(reuters_x_train_padded, reuters_y_train_one_hot, epochs=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 4s 2ms/step\n",
      "loss: 3.132006221866353 accuracy: 0.2506678539891383\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(reuters_x_test_padded, reuters_y_test_one_hot)\n",
    "print('loss: {} accuracy: {}'.format(*scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _gridsearch(lstm_units=[32], activations=['sigmoid'], cutoffs=[220], output_dims=[100]):\n",
    "    table = []\n",
    "    for cutoff in cutoffs:\n",
    "        reuters_x_train_padded = sequence.pad_sequences(reuters_x_train, maxlen=cutoff)\n",
    "        reuters_x_test_padded = sequence.pad_sequences(reuters_x_test, maxlen=cutoff)\n",
    "        for lstm1_units in lstm_units:\n",
    "            for lstm2_units in lstm_units:\n",
    "                for lstm1_activation in activations:\n",
    "                    for lstm2_activation in activations:\n",
    "                        model = Sequential()\n",
    "                        model.add(Embedding(input_dim=len(reuters_map)+3, output_dim=100, input_length=cutoff))\n",
    "                        model.add(LSTM(units=lstm1_units, activation=lstm1_activation, return_sequences=True))#dropout=dropout_1)\n",
    "                        model.add(LSTM(units=lstm2_units, activation=lstm2_activation)) #dropout=dropout_2))\n",
    "                        model.add(Dense(units=46, activation='sigmoid')) # because at the end, we want one yes/no answer\n",
    "                        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "                        model.fit(reuters_x_train_padded, reuters_y_train_one_hot, epochs=1, batch_size=64)\n",
    "                        scores = model.evaluate(reuters_x_test_padded, reuters_y_test_one_hot)\n",
    "                        loss, accuracy = scores[0], scores[1]\n",
    "                        table.append([accuracy, loss, lstm2_activation, lstm1_activation, lstm2_units, lstm1_units, cutoff])\n",
    "                        print(\"ACCURACY: {}, LOSS: {}\".format(accuracy, loss))\n",
    "                        print(\"lstm2_activation: {}, lstm1_activation: {}, lstm2_units: {}, lstm1_units: {}, cutoff: {}\".format(lstm2_activation, lstm1_activation, lstm2_units, lstm1_units, cutoff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "8982/8982 [==============================] - 56s 6ms/step - loss: 3.0527 - categorical_accuracy: 0.3229\n",
      "2246/2246 [==============================] - 4s 2ms/step\n",
      "ACCURACY: 0.36197684778237277, LOSS: 2.524043882944068\n",
      "lstm2_activation: sigmoid, lstm1_activation: sigmoid, lstm2_units: 32, lstm1_units: 32, cutoff: 220\n"
     ]
    }
   ],
   "source": [
    "baseline = gridsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_model(hyperparameters):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=hyperparameters['input_dim'], output_dim=hyperparameters['embedding_out_dim'], input_length=hyperparameters['cutoff']))\n",
    "    model.add(LSTM(units=hyperparameters['lstm1_units'], activation=hyperparameters['lstm1_activation'], return_sequences=True))\n",
    "    model.add(LSTM(units=hyperparameters['lstm2_units'], activation=hyperparameters['lstm2_activation']))\n",
    "    model.add(Dense(units=hyperparameters['output_dim'], activation=hyperparameters['final_activation'])) # because at the end, we want one yes/no answer\n",
    "    model.compile(loss=hyperparameters['loss'], optimizer=hyperparameters['optimizer'], metrics=list(hyperparameters['metrics']))\n",
    "    return model\n",
    "\n",
    "def train_model(model, x_train, y_train, hyperparameters):\n",
    "    model.fit(x_train, y_train, epochs=hyperparameters['epochs'], batch_size=hyperparameters['batch_size'])\n",
    "\n",
    "def test_model(model, x_test, y_test):\n",
    "    scores = model.evaluate(x_test, y_test)\n",
    "    loss, accuracy = scores[0], scores[1]\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': [32],\n",
       " 'cutoff': [220],\n",
       " 'embedding_out_dim': [100],\n",
       " 'epochs': [1],\n",
       " 'final_activation': ['sigmoid'],\n",
       " 'input_dim': [30982],\n",
       " 'loss': ['categorical_crossentropy'],\n",
       " 'lstm1_activation': ['sigmoid', 'tanh', 'relu'],\n",
       " 'lstm1_units': [32, 64],\n",
       " 'lstm2_activation': ['sigmoid'],\n",
       " 'lstm2_units': [32],\n",
       " 'metrics': [('categorical_accuracy',)],\n",
       " 'optimizer': ['adam'],\n",
       " 'output_dim': [46]}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_units = [32, 64]\n",
    "possible_activations = ['sigmoid', 'tanh', 'relu']\n",
    "hyperparameters_possibilities = {\n",
    "    'input_dim': [len(reuters_map)+3], # TODO: find actual value\n",
    "    'output_dim': [46],\n",
    "    'embedding_out_dim': [80, 130],\n",
    "    'cutoff': [180,280],\n",
    "    'lstm1_units': possible_units,\n",
    "    'lstm2_units': possible_units,\n",
    "    'lstm1_activation': possible_activations,\n",
    "    'lstm2_activation': possible_activations,\n",
    "    'final_activation': possible_activations,\n",
    "    'optimizer': ['adam'],\n",
    "    'loss': ['categorical_crossentropy'], #probably shouldn't optimize with this\n",
    "    'metrics': [['categorical_accuracy']],\n",
    "    'batch_size': [32, 128],\n",
    "    'epochs': [1]\n",
    "}\n",
    "hyperparameters_possibilities = {\n",
    "    'input_dim': [len(reuters_map)+3], # TODO: find actual value\n",
    "    'output_dim': [46],\n",
    "    'embedding_out_dim': [100],\n",
    "    'cutoff': [220],\n",
    "    'lstm1_units': possible_units,\n",
    "    'lstm2_units': [32],\n",
    "    'lstm1_activation': possible_activations,\n",
    "    'lstm2_activation': ['sigmoid'],\n",
    "    'final_activation': ['sigmoid'],\n",
    "    'optimizer': ['adam'],\n",
    "    'loss': ['categorical_crossentropy'], #probably shouldn't optimize with this\n",
    "    'metrics': [['categorical_accuracy']],\n",
    "    'batch_size': [32],\n",
    "    'epochs': [1]\n",
    "}\n",
    "hyperparameters_possibilities = {\n",
    "    'input_dim': (len(reuters_map)+3), # TODO: find actual value\n",
    "    'output_dim': (46),\n",
    "    'embedding_out_dim': (100),\n",
    "    'cutoff': (220),\n",
    "    'lstm1_units': (32, 64),\n",
    "    'lstm2_units': (32),\n",
    "    'lstm1_activation': ('sigmoid', 'relu'),\n",
    "    'lstm2_activation': ('sigmoid'),\n",
    "    'final_activation': ('sigmoid'),\n",
    "    'optimizer': ('adam'),\n",
    "    'loss': ('categorical_crossentropy'), #probably shouldn't optimize with this\n",
    "    'metrics': (['categorical_accuracy']),\n",
    "    'batch_size': (32),\n",
    "    'epochs': (1)\n",
    "}\n",
    "hyperparameters_possibilities = {\n",
    "    'input_dim': [len(reuters_map)+3], # TODO: find actual value\n",
    "    'output_dim': [46],\n",
    "    'embedding_out_dim': [100],\n",
    "    'cutoff': [220],\n",
    "    'lstm1_units': possible_units,\n",
    "    'lstm2_units': [32],\n",
    "    'lstm1_activation': possible_activations,\n",
    "    'lstm2_activation': ['sigmoid'],\n",
    "    'final_activation': ['sigmoid'],\n",
    "    'optimizer': ['adam'],\n",
    "    'loss': ['categorical_crossentropy'], #probably shouldn't optimize with this\n",
    "    'metrics': [tuple(['categorical_accuracy'])],\n",
    "    'batch_size': [32],\n",
    "    'epochs': [1]\n",
    "}\n",
    "hyperparameters_possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def get_possible_dicts(dicts):\n",
    "    return [dict(zip(dicts, x)) for x in itertools.product(*dicts.values())]\n",
    "\n",
    "def gridsearch(hyperparameters_possibilities, x_train, y_train, x_test, y_test):\n",
    "#     results = {}\n",
    "    results = {key: {possibility: 0 for possibility in hyperparameters_possibilities[key]} for key in hyperparameters_possibilities}\n",
    "    listed_possibilities = get_possible_dicts(hyperparameters_possibilities)\n",
    "    n = len(listed_possibilities)\n",
    "    for params in listed_possibilities:\n",
    "        if 'cutoff' in params:\n",
    "            x_train_padded = sequence.pad_sequences(x_train, maxlen=params['cutoff'])\n",
    "            x_test_padded = sequence.pad_sequences(x_test, maxlen=params['cutoff'])\n",
    "        else:\n",
    "            x_train_padded = x_train\n",
    "            x_test_padded = x_test\n",
    "#         print(x_train_padded.shape, params['cutoff'])\n",
    "        print(list(params['metrics']))\n",
    "        model = make_model(params)\n",
    "        train_model(model, x_train_padded, y_train, params)\n",
    "        loss, accuracy = test_model(model, x_test_padded, y_test)\n",
    "        for p in params:\n",
    "            results[p][params[p]] += loss\n",
    "#         results[params] = [loss, accuracy]\n",
    "    for key in results:\n",
    "        for possibility in results[key]:\n",
    "            results[key][possibility] = results[key][possibility]/n*len(results[key])\n",
    "    return results\n",
    "\n",
    "# def sort_results(results):\n",
    "#     for key in results.keys()[0]:\n",
    "#         for \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['categorical_accuracy']\n",
      "Epoch 1/1\n",
      "8982/8982 [==============================] - 82s 9ms/step - loss: 2.7606 - categorical_accuracy: 0.3392\n",
      "2246/2246 [==============================] - 4s 2ms/step\n",
      "['categorical_accuracy']\n",
      "Epoch 1/1\n",
      "8982/8982 [==============================] - 88s 10ms/step - loss: 2.8665 - categorical_accuracy: 0.2183\n",
      "2246/2246 [==============================] - 5s 2ms/step\n",
      "['categorical_accuracy']\n",
      "Epoch 1/1\n",
      "8982/8982 [==============================] - 86s 10ms/step - loss: 2.7581 - categorical_accuracy: 0.3387\n",
      "2246/2246 [==============================] - 4s 2ms/step\n",
      "['categorical_accuracy']\n",
      "Epoch 1/1\n",
      "5216/8982 [================>.............] - ETA: 40s - loss: 3.0079 - categorical_accuracy: 0.3123"
     ]
    }
   ],
   "source": [
    "tests = gridsearch(hyperparameters_possibilities, reuters_x_train, reuters_y_train_one_hot, reuters_x_test, reuters_y_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sortby(reward, params):\n",
    "    rewards = {}\n",
    "    for i in range(len(params)):\n",
    "        if params[i] not in rewards:\n",
    "            rewards[params[i]] = [reward[i]]\n",
    "        else:\n",
    "            rewards[params[i]].append(reward[i])\n",
    "    for param in rewards:\n",
    "        rewards[param] = sum(rewards[param])/len(rewards[param])\n",
    "    sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
